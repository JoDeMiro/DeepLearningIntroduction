{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtaCbwhrRZ2zHXBEtBdED0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoDeMiro/DeepLearningIntroduction/blob/main/YOLOv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/26833433/82952157-51b7db00-9f5d-11ea-8f4b-dda1ffecf992.jpg\">\n",
        "\n",
        "\n",
        "<!--- @wandbcode{yolov3-train} -->\n",
        "\n",
        "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n"
      ],
      "metadata": {
        "id": "119RnRH6vk3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Debug YOLOv3 Models with Weights & Biases\n",
        "\n",
        "In this colab,\n",
        "I'll demonstrate how to use the W&B integration with\n",
        "version 3 of the \"You Only Look Once\"\n",
        "(aka [YOLOv5](https://github.com/ultralytics/yolov5))\n",
        "real-time object detection framework\n",
        "to track model metrics,\n",
        "inspect model outputs,\n",
        "and restart interrupted runs."
      ],
      "metadata": {
        "id": "5rCJh8qBvrim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download YOLOv3 Weights\n",
        "\n",
        "Hogy mégis fogalmunk legyen arról, hogy mekkora ez a YOLOv3 model, nem kicsi 265 MByte. Azonban ez nem csak egy modelt tartalmaz, hanem rögötön többet is.\n",
        "\n",
        "Ha időközben az alábbi link megszűnne, akkor a saját gépemen is rajta van."
      ],
      "metadata": {
        "id": "0NmkSwTJIDKB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwfw9w9evjJp",
        "outputId": "99d47872-93cc-47f0-85ac-ca373612e7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-10 19:43:38--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  40.6MB/s    in 6.3s    \n",
            "\n",
            "2022-02-10 19:43:45 (37.7 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Szükség van még néhány konfugurációs fájlra, ahol a YOLO beállításai illetve az osztályok nevei vannak."
      ],
      "metadata": {
        "id": "SNkQfRnyKer9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir cfg\n",
        "!cd cfg\n",
        "!wget https://raw.githubusercontent.com/JoDeMiro/Model/main/YOLOv3/cfg/yolov3.cfg -O cfg/yolov3.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KIDn_MoKXK5",
        "outputId": "e1ea368c-7fd7-44cc-f54b-b1edf4d73198"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘cfg’: File exists\n",
            "--2022-02-10 19:46:23--  https://raw.githubusercontent.com/JoDeMiro/Model/main/YOLOv3/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9129 (8.9K) [text/plain]\n",
            "Saving to: ‘cfg/yolov3.cfg’\n",
            "\n",
            "cfg/yolov3.cfg      100%[===================>]   8.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-10 19:46:23 (66.0 MB/s) - ‘cfg/yolov3.cfg’ saved [9129/9129]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!cd data\n",
        "!wget https://raw.githubusercontent.com/JoDeMiro/Model/main/YOLOv3/COCO/coco.names -O data/coco.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4kB0_8HKyiZ",
        "outputId": "df80ff8a-e760-4d05-d81b-06a0079cfe6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-10 19:47:41--  https://raw.githubusercontent.com/JoDeMiro/Model/main/YOLOv3/COCO/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 705 [text/plain]\n",
            "Saving to: ‘data/coco.names’\n",
            "\n",
            "\rdata/coco.names       0%[                    ]       0  --.-KB/s               \rdata/coco.names     100%[===================>]     705  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-10 19:47:42 (35.7 MB/s) - ‘data/coco.names’ saved [705/705]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ez a későbbiek során majd megoldom, hogy feltöltéssel lehessen a képeket beküldeni, addig álljon itt egy egyszerűbb megoldás.\n",
        "\n",
        "A feldolgozásra váró képeket egy adott könyvtárból fogjuk kiolvasni."
      ],
      "metadata": {
        "id": "Bh9z3gMsLfqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images\n",
        "!cd images\n",
        "!wget https://github.com/JoDeMiro/Data/raw/main/Images/woman1.png -O images/woman1.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnnvK5muLVHa",
        "outputId": "12a98368-7021-48eb-ecee-7715e9775440"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-10 19:50:25--  https://github.com/JoDeMiro/Data/raw/main/Images/woman1.png\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/JoDeMiro/Data/main/Images/woman1.png [following]\n",
            "--2022-02-10 19:50:25--  https://raw.githubusercontent.com/JoDeMiro/Data/main/Images/woman1.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 164047 (160K) [image/png]\n",
            "Saving to: ‘images/woman1.png’\n",
            "\n",
            "images/woman1.png   100%[===================>] 160.20K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-02-10 19:50:25 (6.82 MB/s) - ‘images/woman1.png’ saved [164047/164047]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ezt a részt kihagyom de ha elhasal akkor visszatérünk rá\n",
        "\n",
        "# !cp YOLOV3-Tutorial/pallete ./"
      ],
      "metadata": {
        "id": "dCTYIIWVL86w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLOv3 Inference"
      ],
      "metadata": {
        "id": "RY6R00Q6My66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "\n",
        "import os.path as osp\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n"
      ],
      "metadata": {
        "id": "f_u3QN7RMjzE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ezt át lehetne írni Notebookba is de átláthatatlanul hosszú lenne.\n",
        "\n",
        "%%capture\n",
        "!rm *.py*\n",
        "!wget https://github.com/JoDeMiro/Model/raw/main/YOLOv3/darknet.py\n",
        "!wget https://github.com/JoDeMiro/Model/raw/main/YOLOv3/util.py\n",
        "\n",
        "from darknet import Darknet\n",
        "from util import *"
      ],
      "metadata": {
        "id": "LoQMfGHCSzzo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deffinie arguments\n",
        "\n",
        "# Directory containing images to perform detection upon\n",
        "images: str = 'images'\n",
        "\n",
        "# Directory to store detections to\n",
        "det: str = 'det'\n",
        "\n",
        "# Batch size\n",
        "batch_size: int = 1\n",
        "\n",
        "# Object confidence to filter preidictions\n",
        "confidence: float = 0.5\n",
        "\n",
        "# NMS Threshold\n",
        "nms_thesh: float = 0.4\n",
        "\n",
        "# Cfg file path\n",
        "# cfgfile: str = '\\cfg\\yolov3.cfg'\n",
        "cfgfile: str = 'cfg/yolov3.cfg'\n",
        "\n",
        "# Weights file path\n",
        "weightsfile: str = 'yolov3.weights'\n",
        "\n",
        "# Input resolution of the network. Increase to increase accuracy.\n",
        "resolution: int = 416\n",
        "\n",
        "# Class names\n",
        "class_names_file: str = 'data/coco.names'"
      ],
      "metadata": {
        "id": "QOslDmGOMs1w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "\n",
        "start = 0\n",
        "\n",
        "CUDA = torch.cuda.is_available()\n",
        "\n",
        "# Load Class names\n",
        "fp = open(class_names_file, \"r\")\n",
        "classes = fp.read().split(\"\\n\")[:-1]\n",
        "\n",
        "num_classes = 80                        # Ez úgy jött ki, hogy ennyi\n",
        "                                        # név van a 'data/coco.names'\n",
        "                                        # fájlban.\n",
        "\n",
        "num_classes = len(classes)              # Jobb, amikor a beolvasott\n",
        "                                        # adatokból tudja"
      ],
      "metadata": {
        "id": "ViToA49qPnaF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the neural network\n",
        "\n",
        "print(\"Loading network.....\")\n",
        "model = Darknet(cfgfile)\n",
        "model.load_weights(weightsfile)\n",
        "print(\"Network successfully loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFPXkwogRdDH",
        "outputId": "7026f4fa-a12c-4c61-9169-bc0e1d355fdb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading network.....\n",
            "Network successfully loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the nerual network part two\n",
        "\n",
        "model.net_info[\"height\"] = resolution\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0\n",
        "assert inp_dim > 32\n",
        "\n",
        "# Vannak ilyen szépségek, melyekről ne esik szó a nagy könyvben\n",
        "# például, hogy a model megköveteli, hogy a kép felbontása\n",
        "# 32 többszöröse legyen - még szerencse"
      ],
      "metadata": {
        "id": "qAFfoz9cUlz0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the neural network park tree, hehe\n",
        "\n",
        "# If there's a GPU availible, put the model on GPU\n",
        "if CUDA:\n",
        "    model.cuda()\n",
        "\n",
        "# Set the model in evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyHfZMicU1Oc",
        "outputId": "a9143ddb-1a43-49ca-bf19-c548aac99a35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Darknet(\n",
              "  (module_list): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_0): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (shortcut_4): EmptyLayer()\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_6): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (shortcut_8): EmptyLayer()\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_9): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_10): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (shortcut_11): EmptyLayer()\n",
              "    )\n",
              "    (12): Sequential(\n",
              "      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_12): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (13): Sequential(\n",
              "      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_13): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (14): Sequential(\n",
              "      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_14): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (15): Sequential(\n",
              "      (shortcut_15): EmptyLayer()\n",
              "    )\n",
              "    (16): Sequential(\n",
              "      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_16): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (17): Sequential(\n",
              "      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_17): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (18): Sequential(\n",
              "      (shortcut_18): EmptyLayer()\n",
              "    )\n",
              "    (19): Sequential(\n",
              "      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_19): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (20): Sequential(\n",
              "      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_20): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (21): Sequential(\n",
              "      (shortcut_21): EmptyLayer()\n",
              "    )\n",
              "    (22): Sequential(\n",
              "      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_22): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (23): Sequential(\n",
              "      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_23): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (24): Sequential(\n",
              "      (shortcut_24): EmptyLayer()\n",
              "    )\n",
              "    (25): Sequential(\n",
              "      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_25): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (26): Sequential(\n",
              "      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_26): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (27): Sequential(\n",
              "      (shortcut_27): EmptyLayer()\n",
              "    )\n",
              "    (28): Sequential(\n",
              "      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_28): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (29): Sequential(\n",
              "      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_29): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (30): Sequential(\n",
              "      (shortcut_30): EmptyLayer()\n",
              "    )\n",
              "    (31): Sequential(\n",
              "      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_31): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (32): Sequential(\n",
              "      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_32): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (33): Sequential(\n",
              "      (shortcut_33): EmptyLayer()\n",
              "    )\n",
              "    (34): Sequential(\n",
              "      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_34): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (35): Sequential(\n",
              "      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_35): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (36): Sequential(\n",
              "      (shortcut_36): EmptyLayer()\n",
              "    )\n",
              "    (37): Sequential(\n",
              "      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_37): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (38): Sequential(\n",
              "      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_38): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (39): Sequential(\n",
              "      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_39): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (40): Sequential(\n",
              "      (shortcut_40): EmptyLayer()\n",
              "    )\n",
              "    (41): Sequential(\n",
              "      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_41): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (42): Sequential(\n",
              "      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_42): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (43): Sequential(\n",
              "      (shortcut_43): EmptyLayer()\n",
              "    )\n",
              "    (44): Sequential(\n",
              "      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_44): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (45): Sequential(\n",
              "      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_45): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (46): Sequential(\n",
              "      (shortcut_46): EmptyLayer()\n",
              "    )\n",
              "    (47): Sequential(\n",
              "      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_47): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (48): Sequential(\n",
              "      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_48): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (49): Sequential(\n",
              "      (shortcut_49): EmptyLayer()\n",
              "    )\n",
              "    (50): Sequential(\n",
              "      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_50): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (51): Sequential(\n",
              "      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_51): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (52): Sequential(\n",
              "      (shortcut_52): EmptyLayer()\n",
              "    )\n",
              "    (53): Sequential(\n",
              "      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_53): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (54): Sequential(\n",
              "      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_54): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (55): Sequential(\n",
              "      (shortcut_55): EmptyLayer()\n",
              "    )\n",
              "    (56): Sequential(\n",
              "      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_56): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (57): Sequential(\n",
              "      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_57): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (58): Sequential(\n",
              "      (shortcut_58): EmptyLayer()\n",
              "    )\n",
              "    (59): Sequential(\n",
              "      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_59): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (60): Sequential(\n",
              "      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_60): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (61): Sequential(\n",
              "      (shortcut_61): EmptyLayer()\n",
              "    )\n",
              "    (62): Sequential(\n",
              "      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_62): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (63): Sequential(\n",
              "      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_63): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (64): Sequential(\n",
              "      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_64): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (65): Sequential(\n",
              "      (shortcut_65): EmptyLayer()\n",
              "    )\n",
              "    (66): Sequential(\n",
              "      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_66): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (67): Sequential(\n",
              "      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_67): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (68): Sequential(\n",
              "      (shortcut_68): EmptyLayer()\n",
              "    )\n",
              "    (69): Sequential(\n",
              "      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_69): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (70): Sequential(\n",
              "      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_70): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (71): Sequential(\n",
              "      (shortcut_71): EmptyLayer()\n",
              "    )\n",
              "    (72): Sequential(\n",
              "      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_72): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (73): Sequential(\n",
              "      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_73): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (74): Sequential(\n",
              "      (shortcut_74): EmptyLayer()\n",
              "    )\n",
              "    (75): Sequential(\n",
              "      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_75): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (76): Sequential(\n",
              "      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_76): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (77): Sequential(\n",
              "      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_77): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (78): Sequential(\n",
              "      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_78): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (79): Sequential(\n",
              "      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_79): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (80): Sequential(\n",
              "      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_80): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (81): Sequential(\n",
              "      (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (82): Sequential(\n",
              "      (Detection_82): DetectionLayer()\n",
              "    )\n",
              "    (83): Sequential(\n",
              "      (route_83): EmptyLayer()\n",
              "    )\n",
              "    (84): Sequential(\n",
              "      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_84): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (85): Sequential(\n",
              "      (upsample_85): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    )\n",
              "    (86): Sequential(\n",
              "      (route_86): EmptyLayer()\n",
              "    )\n",
              "    (87): Sequential(\n",
              "      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_87): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (88): Sequential(\n",
              "      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_88): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (89): Sequential(\n",
              "      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_89): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (90): Sequential(\n",
              "      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_90): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (91): Sequential(\n",
              "      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_91): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (92): Sequential(\n",
              "      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_92): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (93): Sequential(\n",
              "      (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (94): Sequential(\n",
              "      (Detection_94): DetectionLayer()\n",
              "    )\n",
              "    (95): Sequential(\n",
              "      (route_95): EmptyLayer()\n",
              "    )\n",
              "    (96): Sequential(\n",
              "      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_96): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (97): Sequential(\n",
              "      (upsample_97): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    )\n",
              "    (98): Sequential(\n",
              "      (route_98): EmptyLayer()\n",
              "    )\n",
              "    (99): Sequential(\n",
              "      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_99): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (100): Sequential(\n",
              "      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_100): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (101): Sequential(\n",
              "      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_101): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (102): Sequential(\n",
              "      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_102): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (103): Sequential(\n",
              "      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_103): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (104): Sequential(\n",
              "      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_104): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              "    )\n",
              "    (105): Sequential(\n",
              "      (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (106): Sequential(\n",
              "      (Detection_106): DetectionLayer()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Olvassuk be a feldolgozásra váró képeket a könyvtárból\n",
        "\n",
        "try:\n",
        "    imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]\n",
        "except NotADirectoryError:\n",
        "    imlist = []\n",
        "    imlist.append(osp.join(osp.realpath('.'), images))\n",
        "except FileNotFoundError:\n",
        "    print (\"No file or directory with the name {}\".format(images))\n",
        "    exit()\n",
        "\n",
        "if not os.path.exists(det):\n",
        "    os.makedirs(det)\n",
        "\n",
        "\n",
        "# --\n",
        "\n",
        "loaded_ims = [cv2.imread(x) for x in imlist]\n",
        "\n",
        "# --\n",
        "\n",
        "def letterbox_image(img, inp_dim):\n",
        "    '''resize image with unchanged aspect ratio using padding'''\n",
        "    img_w, img_h = img.shape[1], img.shape[0]\n",
        "    w, h = inp_dim\n",
        "    new_w = int(img_w * min(w/img_w, h/img_h))\n",
        "    new_h = int(img_h * min(w/img_w, h/img_h))\n",
        "    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
        "\n",
        "    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
        "\n",
        "    return canvas\n",
        "\n",
        "\n",
        "def prep_image(img, inp_dim):\n",
        "    '''\n",
        "    Prepare image for inputting to the neural network.\n",
        "\n",
        "    Returns a Variable\n",
        "    '''\n",
        "    img = (letterbox_image(img, (inp_dim, inp_dim)))\n",
        "    img = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "    img = torch.from_numpy(img).float().div(255.0).unsqueeze(0)\n",
        "    return img\n",
        "\n",
        "# --\n",
        "\n",
        "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
        "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "\n",
        "\n",
        "leftover = 0\n",
        "if (len(im_dim_list) % batch_size):\n",
        "    leftover = 1\n",
        "\n",
        "if batch_size != 1:\n",
        "    num_batches = len(imlist) // batch_size + leftover\n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                        len(im_batches))]))  for i in range(num_batches)]\n",
        "\n",
        "write = 0\n",
        "\n",
        "if CUDA:\n",
        "    im_dim_list = im_dim_list.cuda()"
      ],
      "metadata": {
        "id": "ezDLIGhjV45b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indul a detection"
      ],
      "metadata": {
        "id": "pshLoqQwXodr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(im_batches):\n",
        "#load the image\n",
        "    start = time.time()\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(Variable(batch), CUDA)\n",
        "\n",
        "    prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    if type(prediction) == int:\n",
        "\n",
        "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "            im_id = i*batch_size + im_num\n",
        "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "            print(\"----------------------------------------------------------\")\n",
        "        continue\n",
        "\n",
        "    prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist\n",
        "\n",
        "    if not write:                      #If we have't initialised output\n",
        "        output = prediction\n",
        "        write = 1\n",
        "    else:\n",
        "        output = torch.cat((output,prediction))\n",
        "\n",
        "    for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "        im_id = i*batch_size + im_num\n",
        "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "    if CUDA:\n",
        "        torch.cuda.synchronize()\n",
        "try:\n",
        "    output\n",
        "except NameError:\n",
        "    print (\"No detections were made\")\n",
        "    exit()\n",
        "\n",
        "im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
        "\n",
        "scaling_factor = torch.min(416/im_dim_list,1)[0].view(-1,1)\n",
        "\n",
        "\n",
        "output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
        "output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n",
        "\n",
        "\n",
        "\n",
        "output[:,1:5] /= scaling_factor\n",
        "\n",
        "for i in range(output.shape[0]):\n",
        "    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
        "    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n",
        "\n",
        "\n",
        "output_recast = time.time()\n",
        "class_load = time.time()\n",
        "colors = pkl.load(open(\"pallete\", \"rb\"))\n",
        "colors = get_colors()\n",
        "\n",
        "draw = time.time()\n",
        "\n",
        "\n",
        "def write(x, results):\n",
        "    c1 = tuple(x[1:3].int())\n",
        "    c2 = tuple(x[3:5].int())\n",
        "    img = results[int(x[0])]\n",
        "    cls = int(x[-1])\n",
        "    color = random.choice(colors)\n",
        "    label = \"{0}\".format(classes[cls])\n",
        "    cv2.rectangle(img, c1, c2,color, 1)\n",
        "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
        "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
        "    cv2.rectangle(img, c1, c2,color, -1)\n",
        "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
        "    return img\n",
        "\n",
        "\n",
        "list(map(lambda x: write(x, loaded_ims), output))\n",
        "\n",
        "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(det,x.split(\"/\")[-1]))\n",
        "# det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(det,x.split(\"\\\\\")[-1]))\n",
        "\n",
        "list(map(cv2.imwrite, det_names, loaded_ims))\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"SUMMARY\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "print()\n",
        "# print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
        "# print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
        "# print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", output_recast - start_det_loop))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
        "# print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
        "print(\"----------------------------------------------------------\")\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEZbWp3-X0xW",
        "outputId": "f965c4c1-5dc9-4e09-fba4-8ecb3d813132"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woman1.png           predicted in  1.361 seconds\n",
            "Objects Detected:    person\n",
            "----------------------------------------------------------\n",
            "SUMMARY\n",
            "----------------------------------------------------------\n",
            "Task                     : Time Taken (in seconds)\n",
            "\n",
            "Output Processing        : 0.000\n",
            "Drawing Boxes            : 0.013\n",
            "----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ide kell írni még egy olyat\n",
        "# hogy végig iterál a det könyvtáron és ami kép van benne azt\n",
        "# megjeleníti"
      ],
      "metadata": {
        "id": "IlDbd-8fX0_k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4HTvQmAjbjag"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aEdNIt3nb8fC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}